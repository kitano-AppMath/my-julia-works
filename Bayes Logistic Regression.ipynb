{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63a5c49",
   "metadata": {},
   "source": [
    "# Bayes Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29da12",
   "metadata": {},
   "source": [
    "I train the Bayes logistic model using following methods. \n",
    "1. Laplace approximation\n",
    "2. Assumed density filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75b48a",
   "metadata": {},
   "source": [
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16ad7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "using Statistics\n",
    "using Distributions\n",
    "using LinearAlgebra\n",
    "using Plots\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593ac79",
   "metadata": {},
   "source": [
    "## 1. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5e3186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myADF (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sigmoid function\n",
    "σ(ξ) = 1/(1+exp(-ξ))\n",
    "\n",
    "#logistic model\n",
    "function logistic_model(w,x)\n",
    "    wtx = dot(w,x)\n",
    "    q = σ(wtx)\n",
    "    y = rand(Binomial(1,q))\n",
    "    return y\n",
    "end\n",
    "\n",
    "#model\n",
    "p(y,ϕx,w) = y==1 ? σ(dot(w,ϕx)) : 1-σ(dot(w,ϕx))\n",
    "\n",
    "#gradient of the log likelihood\n",
    "function ∇wloglik(w,Y,ϕX)\n",
    "    N = length(Y)\n",
    "    tmp = zeros(N)\n",
    "    for n in 1:N\n",
    "        tmp[n] = Y[n]-σ(dot(w, ϕX[:,n]))\n",
    "    end\n",
    "    return ϕX * tmp\n",
    "end\n",
    "\n",
    "#gradient descent\n",
    "function gradient_descent(w_init, max_iter, ϵ, α, ∇obj)\n",
    "    w = w_init\n",
    "    p = -∇obj(w)\n",
    "    for k in 1:max_iter\n",
    "        p = -∇obj(w)\n",
    "        if norm(p)<ϵ\n",
    "            return w\n",
    "            break\n",
    "        end\n",
    "        w = w + α*p\n",
    "    end\n",
    "    return w\n",
    "end\n",
    "\n",
    "#split the data\n",
    "function split(X, y, train_size)\n",
    "    N = length(y)\n",
    "    N_train = Int(floor(train_size * N))\n",
    "    N_test = N - N_train\n",
    "    idx = shuffle(1:N)\n",
    "    idx_train = idx[1:N_train]\n",
    "    idx_test = idx[N_train+1:end]\n",
    "    return X[:,idx_train], y[idx_train], X[:,idx_test], y[idx_test], N_train, N_test\n",
    "end\n",
    "\n",
    "#posterior sample (isotropic normal and anistropic mormal distribution)\n",
    "wpost_samps_iso(w_mean, w_var, n_samps) = rand(MvNormal(w_mean, w_var), n_samps)\n",
    "wpost_samps_aniso(w_mean, w_prec, n_samps) = rand(MvNormalCanon(w_mean, w_prec), n_samps)   \n",
    "\n",
    "#predictive didtribution\n",
    "function ysamps(ϕx, wsamps)\n",
    "    _, n_samps = size(wsamps)\n",
    "    preds = zeros(n_samps)\n",
    "    for i in 1:n_samps\n",
    "        preds[i] = p(1, ϕx, wsamps[:,i])\n",
    "    end\n",
    "    prob = mean(preds)\n",
    "    return prob>0.5 ? 1 : 0\n",
    "end\n",
    "\n",
    "#predict Y for test data\n",
    "function pred(ϕX, w_mean, w_var, samp_func)\n",
    "    d,N = size(ϕX)\n",
    "    n_samps = 5000\n",
    "    wsamps = samp_func(w_mean, w_var, n_samps)\n",
    "    Y_preds = zeros(N)\n",
    "    for n in 1:N\n",
    "        Y_preds[n] = ysamps(ϕX[:,n], wsamps)\n",
    "    end\n",
    "    return Y_preds\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    1. Laplace Approximation: get_params returns the posterior mean and precision matrix of Gaussian\n",
    "\"\"\"\n",
    "function get_params(ϕX, Y)\n",
    "    d,N = size(ϕX)\n",
    "    \n",
    "    #calculate the mean\n",
    "    w_init = zeros(d)\n",
    "    max_iter = 10000\n",
    "    ϵ = 1e-1\n",
    "    α = 0.02\n",
    "    ∇obj(w) = w - ∇wloglik(w,Y,ϕX) #-loglik\n",
    "    w_MAP = gradient_descent(w_init, max_iter, ϵ, α, ∇obj)\n",
    "    \n",
    "    #calculate the covariance matrix\n",
    "    prec = I(d)\n",
    "    ϕx = zeros(d)\n",
    "    for n in 1:N\n",
    "        ϕx = ϕX[:,n]\n",
    "        σwtϕx = σ(dot(w_MAP, ϕx))\n",
    "        prec += σwtϕx * (1-σwtϕx) * ϕx * ϕx'\n",
    "    end\n",
    "    return w_MAP, Matrix(Hermitian(prec))\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    2. Assumed Density Filtering (ADF): myADF returns the posterior mean and variation of Gaussian\n",
    "\"\"\"\n",
    "#derivative of logZ\n",
    "function ∇logZ(ϕx, y, μt, st_sq)\n",
    "    c = 1+π*st_sq*norm(ϕx)^2/8\n",
    "    tmp = dot(μt, ϕx)/sqrt(c)\n",
    "    ∇μtmp = ϕx/sqrt(c)\n",
    "    ∂stsqtmp = -dot(μt,ϕx)*norm(ϕx)^2/16/c^(3/2)\n",
    "    ∂μlogZ = y*(1-σ(tmp))*∇μtmp - (1-y)*σ(tmp)*∇μtmp\n",
    "    ∂ssqlogZ = y*(1-σ(tmp))*∂stsqtmp - (1-y)*σ(tmp)*∂stsqtmp\n",
    "    return ∂μlogZ, ∂ssqlogZ\n",
    "end\n",
    "\n",
    "#update the parameters\n",
    "function update_params(ϕX, Y, t, μt, st_sq, d)\n",
    "    ϕx = ϕX[:,t+1]\n",
    "    y = Y[t+1]\n",
    "    ∇μlogZ, ∂ssqlogZ = ∇logZ(ϕx, y, μt, st_sq)\n",
    "    μ_new = μt + st_sq * ∇μlogZ\n",
    "    s_new = st_sq - st_sq^2 * (norm(∇μlogZ)^2 - 2 * ∂ssqlogZ)/d\n",
    "    return μ_new, s_new\n",
    "end\n",
    "\n",
    "#Assumed density filtering\n",
    "function myADF(ϕX, Y, w_mean_init, w_var_init)\n",
    "    d,N = size(ϕX)\n",
    "    w_means = zeros(d,N)\n",
    "    w_vars = zeros(N)\n",
    "    w_means[:,1] = w_mean_init\n",
    "    w_vars[1] = w_var_init\n",
    "    \n",
    "    μt = w_mean_init\n",
    "    st_sq = w_var_init\n",
    "    for t in 1:N-1\n",
    "        μt, st_sq = update_params(ϕX, Y, t, μt, st_sq, d)\n",
    "        w_means[:,t+1] = μt\n",
    "        w_vars[t+1] = st_sq\n",
    "    end\n",
    "    return w_means[:,end], w_vars[end]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca0db8",
   "metadata": {},
   "source": [
    "## 2. create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b023d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true weights: [2.1, -0.7, -1.4, 3.2]\n",
      "N_train=160\n",
      "N_test=40\n",
      "total => class 1: 100, class 0: 100\n",
      "train => class 1: 81, class 0: 79\n",
      "test  => class 1: 19, class 0: 21\n"
     ]
    }
   ],
   "source": [
    "#create the data\n",
    "Random.seed!(42)\n",
    "N = 200\n",
    "\n",
    "#true weights\n",
    "w_true = [2.1, -0.7, -1.4, 3.2] #true weights\n",
    "d = length(w_true)\n",
    "\n",
    "#feature vector\n",
    "ϕX = zeros(d, N)\n",
    "ϕX[1,:] = ones(N)\n",
    "ϕX[2,:] = 3*(rand(N).-0.5)\n",
    "ϕX[3,:] = 2*rand(Normal(0,2), N)\n",
    "ϕX[4,:] = rand(Gamma(3,1.5), N) .- 5\n",
    "\n",
    "#output\n",
    "Y = zeros(N)\n",
    "for n in 1:N\n",
    "    Y[n] = logistic_model(w_true, ϕX[:,n])\n",
    "end\n",
    "\n",
    "#split the data\n",
    "train_size = 0.8\n",
    "ϕX_train, Y_train, ϕX_test, Y_test, N_train, N_test = split(ϕX, Y, train_size)\n",
    "\n",
    "#information about the data\n",
    "println(\"true weights: $(w_true)\")\n",
    "println(\"N_train=$(N_train)\")\n",
    "println(\"N_test=$(N_test)\")\n",
    "println(\"total => class 1: $(Int(sum(Y))), class 0: $(Int(N-sum(Y)))\")\n",
    "println(\"train => class 1: $(Int(sum(Y_train))), class 0: $(Int(N_train-sum(Y_train)))\")\n",
    "println(\"test  => class 1: $(Int(sum(Y_test))), class 0: $(Int(N_test-sum(Y_test)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280098f",
   "metadata": {},
   "source": [
    "## 3. Laplace Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813cd8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior mean of weights: [1.383, -0.491, -1.053, 2.445]\n"
     ]
    }
   ],
   "source": [
    "#Laplace Approximation\n",
    "w_mean, w_prec = get_params(ϕX_train, Y_train)\n",
    "println(\"posterior mean of weights: $(round.(w_mean, digits=3))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a191cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.975\n",
      "test accuracy  = 0.24375\n"
     ]
    }
   ],
   "source": [
    "#prediction for train set \n",
    "Y_train_preds = pred(ϕX_train, w_mean, w_prec, wpost_samps_aniso)\n",
    "println(\"train accuracy = $(sum(Y_train .== Y_train_preds)/N_train)\")\n",
    "\n",
    "#prediction for test set\n",
    "Y_test_preds = pred(ϕX_test, w_mean, w_prec, wpost_samps_aniso)\n",
    "println(\"test accuracy  = $(sum(Y_test .== Y_test_preds)/N_train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a86bb08",
   "metadata": {},
   "source": [
    "## 4. Assumed Density Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83ebfc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posterior mean of weights: [0.813, -0.482, -1.181, 2.509].\n",
      "posterior std of weights: 0.222\n"
     ]
    }
   ],
   "source": [
    "#ADF\n",
    "w_mean_init = zeros(d)\n",
    "w_var_init = 1.0\n",
    "w_mean, w_var = myADF(ϕX_train, Y_train, w_mean_init, w_var_init)\n",
    "println(\"posterior mean of weights: $(round.(w_mean, digits=3)).\")\n",
    "println(\"posterior std of weights: $(round(sqrt(w_var), digits=3))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1500046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.95625\n",
      "test accuracy  = 0.2375\n"
     ]
    }
   ],
   "source": [
    "#prediction for train set \n",
    "Y_train_preds = pred(ϕX_train, w_mean, w_var, wpost_samps_iso)\n",
    "println(\"train accuracy = $(sum(Y_train .== Y_train_preds)/N_train)\")\n",
    "\n",
    "#prediction for test set\n",
    "Y_test_preds = pred(ϕX_test, w_mean, w_var, wpost_samps_iso)\n",
    "println(\"test accuracy  = $(sum(Y_test .== Y_test_preds)/N_train)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
